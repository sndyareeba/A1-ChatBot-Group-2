{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import re\n","import numpy as np\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf"],"metadata":{"id":"04Ok3o9sRSqf","executionInfo":{"status":"ok","timestamp":1720153605239,"user_tz":-180,"elapsed":10559,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","nltk.download('wordnet')"],"metadata":{"id":"pLVQcS_Jopa_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720153605242,"user_tz":-180,"elapsed":34,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}},"outputId":"3181e7cd-cbb5-44bc-bdd4-6ad5990348a4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Loading the dataset\n","data = pd.read_csv('/content/medquad.csv')"],"metadata":{"id":"wZcd73a6RgJM","executionInfo":{"status":"ok","timestamp":1720154301966,"user_tz":-180,"elapsed":464,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Defining text cleaning functions\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","def clean_text(text):\n","    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n","    text = text.lower()\n","    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n","    return text"],"metadata":{"id":"fOOQeQNFRjQN","executionInfo":{"status":"ok","timestamp":1720154305912,"user_tz":-180,"elapsed":5,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","# Applying cleaning functions to the dataset\n","data['question'] = data['question'].astype(str).apply(clean_text)\n","data['answer'] = data['answer'].astype(str).apply(clean_text)\n","\n","# Use a smaller subset of the data for initial testing\n","data = data.sample(frac=0.5, random_state=42)"],"metadata":{"id":"hqGPpv6tRtBS","executionInfo":{"status":"ok","timestamp":1720154315590,"user_tz":-180,"elapsed":7368,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Defining hyperparameters\n","MAX_SEQUENCE_LENGTH = 50\n","VOCABULARY_SIZE = 2000\n","EMBEDDING_DIM = 64\n","LSTM_UNITS = 256"],"metadata":{"id":"v8GVdZAoR1cs","executionInfo":{"status":"ok","timestamp":1720154319975,"user_tz":-180,"elapsed":511,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Tokenization\n","tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n","tokenizer.fit_on_texts(data['question'].tolist() + data['answer'].tolist())\n","\n","# Encoding sequences\n","question_sequences = tokenizer.texts_to_sequences(data['question'].tolist())\n","answer_sequences = tokenizer.texts_to_sequences(data['answer'].tolist())\n","question_sequences = pad_sequences(question_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n","answer_sequences = pad_sequences(answer_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"],"metadata":{"id":"e0RK6-alR5vv","executionInfo":{"status":"ok","timestamp":1720154324133,"user_tz":-180,"elapsed":1250,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# One-hot encoding the target sequences\n","answer_sequences = np.array([tf.keras.utils.to_categorical(seq, num_classes=VOCABULARY_SIZE) for seq in answer_sequences])"],"metadata":{"id":"ZYEAumjXSCgS","executionInfo":{"status":"ok","timestamp":1720154330146,"user_tz":-180,"elapsed":3563,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Splitting the data to train and test the model\n","X_train, X_test, y_train, y_test = train_test_split(question_sequences, answer_sequences, test_size=0.2, random_state=42)"],"metadata":{"id":"wCTqh2BgSEpN","executionInfo":{"status":"ok","timestamp":1720154332180,"user_tz":-180,"elapsed":504,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Encoder\n","encoder_inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))\n","encoder_embedding = Embedding(VOCABULARY_SIZE, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(encoder_inputs)\n","encoder_lstm = LSTM(LSTM_UNITS, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n","encoder_states = [state_h, state_c]\n","\n","# Decoder\n","decoder_inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))\n","decoder_embedding = Embedding(VOCABULARY_SIZE, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(decoder_inputs)\n","decoder_lstm = LSTM(LSTM_UNITS, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","decoder_dense = Dense(VOCABULARY_SIZE, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"I3tX5P5HSJMM","executionInfo":{"status":"ok","timestamp":1720154336380,"user_tz":-180,"elapsed":467,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# This model turns\n","# encoder_input_data & decoder_input_data into decoder_target_data\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"metadata":{"id":"dCobeWfOSP85","executionInfo":{"status":"ok","timestamp":1720154340382,"user_tz":-180,"elapsed":478,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"a5MORrshSe8H","executionInfo":{"status":"ok","timestamp":1720154342792,"user_tz":-180,"elapsed":3,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Callbacks for better training\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"],"metadata":{"id":"y-Fx8YPUSkHG","executionInfo":{"status":"ok","timestamp":1720154345289,"user_tz":-180,"elapsed":3,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Training the model\n","model.fit([X_train, X_train], y_train, epochs=20, batch_size=32, validation_data=([X_test, X_test], y_test), callbacks=[checkpoint, early_stopping])"],"metadata":{"id":"wicLrVk2Snuj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720156046168,"user_tz":-180,"elapsed":1697235,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}},"outputId":"fdac33fe-2522-49b8-a1ec-c1bdf651eb14"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","206/206 [==============================] - 81s 378ms/step - loss: 5.9295 - accuracy: 0.1546 - val_loss: 5.7364 - val_accuracy: 0.1649\n","Epoch 2/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["206/206 [==============================] - 77s 372ms/step - loss: 5.5361 - accuracy: 0.1771 - val_loss: 5.3609 - val_accuracy: 0.1861\n","Epoch 3/20\n","206/206 [==============================] - 76s 370ms/step - loss: 5.2133 - accuracy: 0.1992 - val_loss: 5.1894 - val_accuracy: 0.2029\n","Epoch 4/20\n","206/206 [==============================] - 77s 372ms/step - loss: 5.0360 - accuracy: 0.2156 - val_loss: 5.0272 - val_accuracy: 0.2129\n","Epoch 5/20\n","206/206 [==============================] - 82s 398ms/step - loss: 4.8951 - accuracy: 0.2340 - val_loss: 4.9541 - val_accuracy: 0.2115\n","Epoch 6/20\n","206/206 [==============================] - 77s 373ms/step - loss: 4.7939 - accuracy: 0.2523 - val_loss: 4.8885 - val_accuracy: 0.2567\n","Epoch 7/20\n","206/206 [==============================] - 78s 378ms/step - loss: 4.7341 - accuracy: 0.2651 - val_loss: 4.8330 - val_accuracy: 0.2718\n","Epoch 8/20\n","206/206 [==============================] - 77s 374ms/step - loss: 4.6678 - accuracy: 0.2776 - val_loss: 4.7926 - val_accuracy: 0.2676\n","Epoch 9/20\n","206/206 [==============================] - 77s 374ms/step - loss: 4.6191 - accuracy: 0.2942 - val_loss: 4.7572 - val_accuracy: 0.2761\n","Epoch 10/20\n","206/206 [==============================] - 77s 373ms/step - loss: 4.5925 - accuracy: 0.2905 - val_loss: 4.8005 - val_accuracy: 0.2158\n","Epoch 11/20\n","206/206 [==============================] - 77s 372ms/step - loss: 4.5560 - accuracy: 0.2982 - val_loss: 4.7080 - val_accuracy: 0.2947\n","Epoch 12/20\n","206/206 [==============================] - 77s 373ms/step - loss: 4.5438 - accuracy: 0.3060 - val_loss: 4.6945 - val_accuracy: 0.2960\n","Epoch 13/20\n","206/206 [==============================] - 77s 376ms/step - loss: 4.4864 - accuracy: 0.3095 - val_loss: 4.7057 - val_accuracy: 0.2933\n","Epoch 14/20\n","206/206 [==============================] - 77s 373ms/step - loss: 4.4548 - accuracy: 0.3115 - val_loss: 4.6774 - val_accuracy: 0.2959\n","Epoch 15/20\n","206/206 [==============================] - 77s 375ms/step - loss: 4.4330 - accuracy: 0.3101 - val_loss: 4.6589 - val_accuracy: 0.2990\n","Epoch 16/20\n","206/206 [==============================] - 77s 372ms/step - loss: 4.4077 - accuracy: 0.3129 - val_loss: 4.6610 - val_accuracy: 0.2975\n","Epoch 17/20\n","206/206 [==============================] - 76s 371ms/step - loss: 4.3918 - accuracy: 0.3139 - val_loss: 4.6602 - val_accuracy: 0.2968\n","Epoch 18/20\n","206/206 [==============================] - 77s 374ms/step - loss: 4.3765 - accuracy: 0.3139 - val_loss: 4.6631 - val_accuracy: 0.2925\n","Epoch 19/20\n","206/206 [==============================] - 77s 374ms/step - loss: 4.4048 - accuracy: 0.3054 - val_loss: 4.6844 - val_accuracy: 0.2942\n","Epoch 20/20\n","206/206 [==============================] - 77s 373ms/step - loss: 4.5332 - accuracy: 0.2886 - val_loss: 4.9419 - val_accuracy: 0.2242\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7fc0a1126980>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Defining the encoder model\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","# Defining the decoder model\n","decoder_state_input_h = Input(shape=(LSTM_UNITS,))\n","decoder_state_input_c = Input(shape=(LSTM_UNITS,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_embedding_inference = Embedding(VOCABULARY_SIZE, EMBEDDING_DIM, input_length=1)\n","decoder_inputs_single = Input(shape=(1,))\n","decoder_embedding_single = decoder_embedding_inference(decoder_inputs_single)\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_embedding_single, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model(\n","    [decoder_inputs_single] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"metadata":{"id":"83KtiSfjaUhE","executionInfo":{"status":"ok","timestamp":1720156204464,"user_tz":-180,"elapsed":15658,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Function to generate responses\n","def decode_sequence(input_seq):\n","    # Encoding the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generating empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1))\n","\n","    # Populating the first character of target sequence with the start character from input_seq.\n","    target_seq[0, 0] = input_seq[0, 0]\n","\n","    # Sampling loop for a batch of sequences\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = tokenizer.index_word.get(sampled_token_index, '')\n","\n","        decoded_sentence += ' ' + sampled_char\n","\n","        # Exit condition: either hit max length or find stop character.\n","        if len(decoded_sentence.split()) > MAX_SEQUENCE_LENGTH or sampled_char == '':\n","            stop_condition = True\n","\n","        # Updating the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence.strip()\n"],"metadata":{"id":"1nCTS3vlSyHk","executionInfo":{"status":"ok","timestamp":1720156209204,"user_tz":-180,"elapsed":460,"user":{"displayName":"Jeff Munyigi","userId":"18089865518275722451"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# User prompt for input\n","while True:\n","    input_text = input(\"You: \")\n","    if input_text.lower() in ['quit', 'exit']:\n","        break\n","    input_text = '/' + ' ' + input_text\n","    input_seq = tokenizer.texts_to_sequences([clean_text(input_text)])\n","    input_seq = pad_sequences(input_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n","    response = decode_sequence(input_seq)\n","    print(\"Bot:\", response)\n"],"metadata":{"id":"1X8f0MaAS0_I","collapsed":true},"execution_count":null,"outputs":[]}]}